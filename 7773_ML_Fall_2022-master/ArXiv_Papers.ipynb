{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\V}{\\mathbf{V}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\E}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Adversarial Examples\n",
    "\n",
    "- [Robust Physical-World Attacks on Deep Learning Models](https://arxiv.org/abs/1707.08945)\n",
    "- [The Surprising Creativity of Digital Evolution: ...](https://arxiv.org/pdf/1803.03453v1.pdf)\n",
    "  \n",
    "Attention\n",
    "- [Attention paper, original](https://arxiv.org/abs/1409.0473)\n",
    "- [simplification of attention paper](https://arxiv.org/abs/1508.04025)\n",
    "- [Attention is all you need](https://arxiv.org/abs/1706.03762)\n",
    "- [An Analysis of BERT's Attention](https://arxiv.org/pdf/1906.04341.pdf)\n",
    "- [Show, Attend, and Tell paper](https://arxiv.org/pdf/1502.03044.pdf)\n",
    "\n",
    "Autoencoders\n",
    "- [Kigma, original paper](https://arxiv.org/abs/1312.6114)\n",
    "- [Widely referenced tutorial on VAE](https://arxiv.org/abs/1606.05908)\n",
    "- [VQ-VAE2](https://arxiv.org/abs/1906.00446)\n",
    "- [Discrete VAE](https://arxiv.org/abs/1609.02200)\n",
    "- [VQ VAE](https://arxiv.org/pdf/1711.00937.pdf)\n",
    "- [VQ-VAE-2 paper](https://arxiv.org/pdf/1906.00446.pdf)\n",
    "- [Variational Lossy Autoencoder](https://arxiv.org/pdf/1611.02731.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "CelebA_01_deep_convolutional_generative_adversarial_network.ipynb\n",
    "\n",
    "\n",
    "CNN\n",
    "- [A guide to convolutional arithmetic for deep learning](https://arxiv.org/pdf/1603.07285.pdf)\n",
    "- [Zeiler and Fergus](https://arxiv.org/abs/1311.2901)\n",
    "- [Bag of Tricks for Image Classification with CNNs](https://arxiv.org/abs/1812.01187)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "BERT, ELMO\n",
    "- [ELMo paper](https://arxiv.org/abs/1802.05365)\\n\",\n",
    "- [Howard and Ruder](https://arxiv.org/abs/1801.06146)\"\n",
    "- [Reformer](https://arxiv.org/pdf/2001.04451.pdf)\\n\",\n",
    "\n",
    "CLIP\n",
    "- [LiT paper](https://arxiv.org/pdf/2111.07991.pdf)\n",
    "- [CLIP](https://arxiv.org/abs/2204.06125)\n",
    "\n",
    "\n",
    "DALL-E\n",
    "- [DALL-E](https://arxiv.org/pdf/2102.12092.pdf)\n",
    "- [PixelCNN paper](https://arxiv.org/pdf/1606.05328.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "GAN\n",
    "- [GAN](https://arxiv.org/pdf/1406.2661.pdf) \n",
    "- [Goodfellow GAN tutorial](https://arxiv.org/pdf/1701.00160.pdf)\n",
    "- [GAN Theory](https://arxiv.org/pdf/1412.6515.pdf)\n",
    "- [Huszar: How to train your GAN](https://arxiv.org/pdf/1511.05101.pdf)\n",
    "- [Improved techniques for training GANs](https://arxiv.org/pdf/1606.03498.pdf)\n",
    "- [Pros and Cons of GAN Evaluation Measures](https://arxiv.org/pdf/2103.09396.pdf)\n",
    "- [Deep Convolutional GAN](https://arxiv.org/abs/1511.06434)\n",
    "- [Frechet distance vs Inception score](https://arxiv.org/abs/1801.01973)\n",
    "- [Pix2Pix](https://arxiv.org/abs/1611.07004)\n",
    "- [Generative Teaching Network](https://arxiv.org/abs/1912.07768)\n",
    "- [Wasserstein GAN](https://arxiv.org/pdf/1701.07875.pdf)\n",
    "- [Wasserstein GAN: blog](https://arxiv.org/pdf/1904.08994.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "NLP\n",
    "\n",
    "- [CNN for sentence classification](https://arxiv.org/abs/1408.5882)\\n\",\n",
    "- [k-max pooling over time](https://arxiv.org/pdf/1404.2188.pdf)\"\n",
    "- [CNN for sentence classification](https://arxiv.org/abs/1408.5882)\\n\",\n",
    "- [Recent developments, good survey](https://arxiv.org/pdf/1708.02709.pdf)\\n\",\n",
    "- [GPT 3](https://arxiv.org/abs/2005.14165)\n",
    "\n",
    "Neural Style Transfer\n",
    "- [Gatys: A Neural Algorithm for Style](https://arxiv.org/abs/1508.06576)\\n\","
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Synthetic Data\n",
    "- [Classifier based metrics](https://arxiv.org/pdf/1907.06673.pdf)\n",
    "- [Quality metrics](https://arxiv.org/pdf/1802.03446.pdf) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Time GAN\n",
    "- [Time GAN](https://proceedings.neurips.cc/paper/2019/file/c9efe5f26cd17ba6216bbe2a7d26d490-Paper.pdf)\n",
    "- [Survey: GAN for Timeseries](https://arxiv.org/pdf/2107.11098.pdf)\n",
    "- [Quant GAN](https://arxiv.org/abs/1907.06673)\n",
    "- [FU: CGAN](https://arxiv.org/pdf/1904.11419.pdf)\n",
    "- [SeqGAN](https://arxiv.org/abs/1609.05473)\n",
    "- [C-RNN-GAN: Music](https://arxiv.org/pdf/1611.09904.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Training\n",
    "- [Gradient Descent variations: Simon Ruder survey](https://arxiv.org/abs/1609.04747)\n",
    "- [The Lottery Ticket Hypothesis](https://arxiv.org/abs/1803.03635)\n",
    "- [Kaiming et al](https://arxiv.org/pdf/1502.01852.pdf)\n",
    "- [Batch Normalization paper](https://arxiv.org/abs/1502.03167)\n",
    "- [Fixup initialization paper](https://arxiv.org/abs/1901.09321)\n",
    "- [Label Smoothing paper](https://arxiv.org/pdf/1701.06548.pdf)\n",
    "- [Mixup training paper](https://arxiv.org/abs/1905.11001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Transfer Learning\n",
    "- [T5: Limits of Transfer Learning](https://arxiv.org/pdf/1910.10683.pdf)\n",
    "\n",
    "Transformer\n",
    "- [Taming Transformers for High Resolution Image Synthesis](https://arxiv.org/pdf/2012.09841.pdf)\n",
    "- [Vision Transforme](https://arxiv.org/pdf/2010.11929.pdf)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
