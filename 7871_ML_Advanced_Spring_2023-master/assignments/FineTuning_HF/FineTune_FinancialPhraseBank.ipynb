{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\V}{\\mathbf{V}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\Reals}{{\\mathbb{R}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\Emb}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "\\def\\OrderOf#1{\\mathcal{O}\\left( #1 \\right)}\n",
       "%\n",
       "% Expectation operator\n",
       "\\def\\Exp#1{\\underset{#1} {\\operatorname{\\mathbb{E}}} }\n",
       "%\n",
       "% Reinforcement learning\n",
       "\\newcommand{\\Actions}{{\\mathcal{A}}} \n",
       "\\newcommand{\\actseq}{A}\n",
       "\\newcommand{\\act}{a}\n",
       "\\newcommand{\\States}{{\\mathcal{S}}}   \n",
       "\\newcommand{\\stateseq}{S}  \n",
       "\\newcommand{\\state}{s}\n",
       "\\newcommand{\\Rewards}{{\\mathcal{R}}}\n",
       "\\newcommand{\\rewseq}{R}\n",
       "\\newcommand{\\rew}{r}\n",
       "\\newcommand{\\transp}{P}\n",
       "\\newcommand{\\statevalfun}{v}\n",
       "\\newcommand{\\actvalfun}{q}\n",
       "\\newcommand{\\disc}{\\gamma}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run \"../../Latex_macros.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Assignment\n",
    "\n",
    "In this assignment you will use the Unsupervised Pre-Training + Supervised Fine-Tuning paradigm.\n",
    "\n",
    "The objective is to wind up with a model that can perform Sentiment Analysis on sentences from\n",
    "a Financial domain.\n",
    "\n",
    "Specifically\n",
    "- you will choose a Pre-Trained Language Model from the HuggingFace platform\n",
    "- Fine-Tune the model on the Financial PhraseBank dataset\n",
    "    - a collection of hand-annotated sentences with sentiment classified a Negative, Neutral, Positive\n",
    "\n",
    "The assignment will consist of\n",
    "- a \"basic\" part\n",
    "    - This is the minimum that you must submit (and succeed on)  in order to earn a passing grade\n",
    "- \"extras\"\n",
    "    - more challenging objectives \n",
    "    - earn points beyond the basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Financial PhraseBank dataset\n",
    "\n",
    "The dataset was created as part of a research paper in Finance.\n",
    "\n",
    "There were several humans who labeled the sentiment of sentences.  Naturally humans don't always agree.\n",
    "Thus, the dataset has several \"flavors\" (called \"subsets\") based on the fraction of annotators who\n",
    "agree.\n",
    "\n",
    "As part of the \"basic\" assignment, you should use the \"all agree\" flavor.\n",
    "\n",
    "There are multiple ways to access this dataset.\n",
    "- The preferred way: as a [HuggingFace dataset](https://huggingface.co/datasets/financial_phrasebank)\n",
    "- Discouraged: as a [TFDS](https://www.tensorflow.org/datasets/community_catalog/huggingface/financial_phrasebank)\n",
    "    - this is discouraged *only* because there will be an \"extra\" part asking you to convert the HuggingFace dataset to a TFDS\n",
    "    - you won't get credit for this \"extra\" if you obtain it directly as a TFDS !\n",
    "- Discouraged: From the [authors](https://www.researchgate.net/publication/251231364_FinancialPhraseBank-v10)\n",
    "    - the \"Download the PDF\" link contains an archive file with the data\n",
    "    - this is discouraged only because it involves extra work\n",
    "    - but you might find it handy in creating your own TFDS in the \"extra\" part\n",
    "    \n",
    "You don't need to understand the paper but here is a [reference](https://arxiv.org/pdf/1307.5336.pdf#page=9)\n",
    "to the paper that introduced it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Choose a Pre-Trained Language Model from the HuggingFace platform\n",
    "\n",
    "There are lots of Language Models on HuggingFace.  They vary by, among other things\n",
    "- model size\n",
    "- training objective\n",
    "- language of training data\n",
    "\n",
    "An important consideration is computational\n",
    "- the model fits in the memory of the machine you are using\n",
    "- the execution time is rapid enough for you to experiment\n",
    "    - it will help to have a machine with a GPU (e.g., Google Colab)\n",
    "\n",
    "You are free to choose *subject to limitations*\n",
    "- the model should *not* have already been trained on a Financial dataset\n",
    "    - e.g., you may not use FinBERT\n",
    "\n",
    "I can verify that the choice of `distilbert-base-uncased` is feasible when using the free version of Google Colab\n",
    "\n",
    "One of the options for extra credit is to experiment with different models and report and explain the differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Submission requirements\n",
    "\n",
    "You will submit a Jupyter notebook that follows the steps in\n",
    "the [Recipe for Machine Learning](https://github.com/kenperry-public/ML_Fall_2022/blob/master/Recipe_Overview.ipynb)\n",
    "\n",
    "That is, rather than just submitting a final model\n",
    "- you should follow the steps  (as appropriate) in the Recipe\n",
    "- treat the notebook as a movie showing\n",
    "    - the Recipe steps that you took\n",
    "        - Exploratory Data analysis and Error Analysis are steps that are ignored at your own peril   \n",
    "    - including steps that led to failure (e.g., bad choices)\n",
    "        - what you learned from the failure\n",
    "        - how you overcame it or learned to make a different choice\n",
    "        \n",
    "Use Markup in Jupyter rather than code comments to convey your thoughts.\n",
    "\n",
    "Use Section Headings to clearly indicate different parts of the assignment and different experiments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Your code should be TensorFlow/Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Discussion\n",
    "\n",
    "In each part, or each experiment, I would like to see a Discussion of results\n",
    "- Can you conclude that your choices led to better of worse out of sample performance ?\n",
    "- Do you have a theory as to why the performance changed/did not change ?\n",
    "\n",
    "The objective is to get you to think like a scientist rather than just completing a task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Originality\n",
    "\n",
    "There are no doubt published notebooks that use this dataset for a similar purpose.\n",
    "\n",
    "The work that you submit should be your own.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Getting started\n",
    "\n",
    "The HuggingFace course is a great way to get up to speed on various aspects of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Basic part of assignment\n",
    "\n",
    "There are several sub-parts. \n",
    "- Fine-tune *only the Classifier head*\n",
    "- Fine-tune *all* the weights\n",
    "\n",
    "You will present a discussion of whether your out of sample performance was significantly improved\n",
    "by one of the two sub-parts.\n",
    "\n",
    "The Basic part allows you several simplifications\n",
    "- your model fitting can take features/labels that are Python data structures\n",
    "    - these are most familiar to you\n",
    "    - obtained from the dataset\n",
    "- you can using a HuggingFace model that already comes with a Classifier head\n",
    "\n",
    "I suggest that one section of your notebook clearly demonstrates success on the Basic Part.\n",
    "- Walk before you try running\n",
    "- Extra parts should be distinct suggestions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Extras\n",
    "\n",
    "You can demonstrate greater skill (and earn more points) by completing some extra parts.\n",
    "\n",
    "After each extra, please complete a Discussion section as you did for the Basic part.\n",
    "\n",
    "My suggestions follow, but I'm open to your ideas.\n",
    "\n",
    "I will determine the amount of extra points by my perception of the difficulty of each extra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Create (and fit the model with) a TensorFlow Dataset (TFDS)\n",
    "\n",
    "*Relative difficulty*: low to medium\n",
    "\n",
    "The dataset is sufficiently small to fit into memory on a free Google Colab machine.\n",
    "\n",
    "In this part, I want you to *pretend* that your machine is not big enough to fit all the data into memory.\n",
    "\n",
    "You will create a TFDS and use this in the model fitting.\n",
    "\n",
    "\n",
    "*Starting off with the HuggingFace dataset*, create a TFDS with the same data\n",
    "- use this TFDS in the \"fit\" statement of the model\n",
    "    - manipulate the data as much as possible using TFDS operations\n",
    "        - e.g., if you need to shuffle the examples, use TFDS operations rather than shuffling before creating the TFDS\n",
    "    - it's OK to load the entire HuggingFace dataset into memory for the purpose of creating the TFDS\n",
    "- *you may not start off with a dataset that is already a TFDS*\n",
    "\n",
    "The objective is for you to demonstrate skill with TFDS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Create your own Classification head\n",
    "\n",
    "*Relative difficulty*: medium to hard\n",
    "\n",
    "Rather than using a Classification head automatically provided with the HuggingFace model\n",
    "- you will obtain a head-less model from HugginFace\n",
    "- you will add your own Classification head\n",
    "    - with as many layers as you like\n",
    "    \n",
    "The objective is for you to demonstrate some skills with the Keras Functional Model API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Use different \"flavors\" of the dataset\n",
    "\n",
    "*Relative difficulty*: low, but time-consuming\n",
    "\n",
    "The basic part used examples on which all annotators agreed.\n",
    "\n",
    "Try different flavors and discuss the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Address any Imbalanced Data issues\n",
    "\n",
    "*Relative difficulty: low*\n",
    "\n",
    "- If the distribution between labels in the dataset is not uniform, you may want to address the imbalance\n",
    "\n",
    "## Superior Error Analysis\n",
    "\n",
    "*Relative difficulty: medium*\n",
    "\n",
    "Rather than just reporting a single summary statistic for out of sample performance, analyze the results in detail\n",
    "- Is one class harder to correctly classify than others\n",
    "- Is there some systematic pattern of errors\n",
    "    - e.g., characteristics of input sentences that are more difficult to correctly classify\n",
    "    \n",
    "Try to use the results of this analysis to improve the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Experiment with different Pre-Trained models\n",
    "\n",
    "*Relative difficulty*: low, but time-consuming\n",
    "\n",
    "Try several different pre-trained Language Models.\n",
    "\n",
    "Discuss the results.  For example\n",
    "- does a bigger pre-trained model lead to better results\n",
    "    - before and after fine-tuning all the weights\n",
    "- does the type of data on which the model was trained make a difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Experiment with Fine-Tuning\n",
    "\n",
    "*Relative difficulty*: low, but time-consuming\n",
    "\n",
    "Does out of sample performance vary with changing\n",
    "- the number of examples in Fine-Tuning\n",
    "    - what is the smallest number that you think is sufficient\n",
    "- there are many choices of proper subsets of a given size\n",
    "    - does it matter which one you choose ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## In-context learning\n",
    "\n",
    "*Relative difficulty: low but fun !*\n",
    "\n",
    "Can you use few-shot learning successfully (i.e., no further training) ?\n",
    "\n",
    "It would be great to do this for Financial PhraseBank but the sentences may be too long\n",
    "- pre-trained models have maximum sequence lengths that may be too small\n",
    "\n",
    "Propose some interesting task related to Finance and try to achieve Few Shot Learning on the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
